{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/pytorch_basics/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. Basic autograd example 1        \n",
    "2. Basic autograd example 2              \n",
    "3. Loading data from numpy                \n",
    "4. Input pipline                         \n",
    "5. Input pipline for custom dataset    \n",
    "6. Pretrained model       \n",
    "7. Save and load model                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic autograd example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "#                     1. Basic autograd example 1                    #\n",
    "# ================================================================== #\n",
    "\n",
    "# Create tensors.\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "\n",
    "# Compute gradients.\n",
    "y.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print(x.grad)    # x.grad = 2 \n",
    "print(w.grad)    # w.grad = 1 \n",
    "print(b.grad)    # b.grad = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create tensors**\n",
    "\n",
    "`requires_grad=True` говорит, что мы хотим вычислить градиент относительно тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a computational graph**\n",
    "\n",
    "$y = 2x + 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = w * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute gradients**\n",
    "\n",
    "Запускается процесс обратного распространения ошибки (backpropagation) для вычисления градиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out the gradients**\n",
    "\n",
    "Градиенты хранятся в атрибуте .grad каждого тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)    # x.grad = 2 \n",
    "print(w.grad)    # w.grad = 1 \n",
    "print(b.grad)    # b.grad = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic autograd example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "#                    2. Basic autograd example 2                     #\n",
    "# ================================================================== #\n",
    "\n",
    "# Create tensors of shape (10, 3) and (10, 2).\n",
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)\n",
    "\n",
    "# Build a fully connected layer.\n",
    "linear = nn.Linear(3, 2)\n",
    "print ('w: ', linear.weight)\n",
    "print ('b: ', linear.bias)\n",
    "\n",
    "# Build loss function and optimizer.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "for i in range(100):\n",
    "    # Forward pass.\n",
    "    pred = linear(x)\n",
    "\n",
    "    # Compute loss.\n",
    "    loss = criterion(pred, y)\n",
    "    print(i, 'loss: ', loss.item())\n",
    "\n",
    "    # Backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Print out the gradients.\n",
    "    #print ('dL/dw: ', linear.weight.grad) \n",
    "    #print ('dL/db: ', linear.bias.grad)\n",
    "\n",
    "    # 1-step gradient descent.\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "# You can also perform gradient descent at the low level.\n",
    "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
    "# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
    "\n",
    "# Print out the loss after 1-step gradient descent.\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 1 step optimization: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ДАННЫЕ, ПРЕОБРАБОТКА ДАННЫХ**\n",
    "\n",
    "Create tensors of shape (10, 3) and (10, 2)\n",
    "\n",
    "Создаются два случайных тензора. Они будут использоваться как входные данные (функции) и целевые значения для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. НЕЙРОСЕТЬ**\n",
    "\n",
    "Build a fully connected layer\n",
    "\n",
    "Создается полносвязный слой. Это означает, что слой принимает входные данные размерности 3 и возвращает выходные данные размерности 2. Этот слой будет использоваться для предсказания целевых значений на основе входных данных x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[-0.5238, -0.5095, -0.5385],\n",
      "        [-0.4251,  0.2229, -0.5677]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([ 0.5173, -0.3859], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(3, 2)\n",
    "print ('w: ', linear.weight)\n",
    "print ('b: ', linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. LOSS & OPTIM**\n",
    "\n",
    "Build loss function and optimizer\n",
    "\n",
    "Создается функция потерь (MSE - Mean Squared Error) и оптимизатор (SGD - Stochastic Gradient Descent) с коэффициентом скорости обучения (learning rate) 0.01. Оптимизатор будет использоваться для обновления весов и смещения (bias) слоя linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. ОБУЧЕНИЕ МОДЕЛИ**\n",
    "\n",
    "Цикл выполняется 100 раз, что означает, что модель обучается на данных в течение 100 эпох\n",
    "\n",
    "**1. Forward pass**\n",
    "\n",
    "Прямой проход (Forward Pass): Вычисляются прогнозы модели, передавая входные данные x через слой linear\n",
    "\n",
    "**2. Compute loss**\n",
    "\n",
    "Вычисление функции потерь: Сравниваются прогнозы с целевыми значениями y, и вычисляется средняя квадратичная ошибка (MSE)\n",
    "\n",
    "**3. Backward pass**\n",
    "\n",
    "Обратное распространение (Backward Pass): Вычисляются градиенты функции потерь по отношению к весам и смещению слоя linear\n",
    "\n",
    "**4. 1-step gradient descent**\n",
    "\n",
    "Шаг оптимизации: Выполняется один шаг градиентного спуска с помощью `optimizer.step()` для обновления параметров слоя linear\n",
    "\n",
    "Обнуление градиентов: Градиенты обнуляются с помощью `optimizer.zero_grad()`, чтобы гарантировать, что они не накапливаются при каждой итерации цикла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  2.3026278018951416\n",
      "1 loss:  2.236931324005127\n",
      "2 loss:  2.174152374267578\n",
      "3 loss:  2.11415433883667\n",
      "4 loss:  2.0568082332611084\n",
      "5 loss:  2.001991033554077\n",
      "6 loss:  1.9495846033096313\n",
      "7 loss:  1.8994779586791992\n",
      "8 loss:  1.8515640497207642\n",
      "9 loss:  1.8057419061660767\n",
      "10 loss:  1.7619149684906006\n",
      "11 loss:  1.7199913263320923\n",
      "12 loss:  1.679883599281311\n",
      "13 loss:  1.6415084600448608\n",
      "14 loss:  1.6047859191894531\n",
      "15 loss:  1.569641351699829\n",
      "16 loss:  1.5360019207000732\n",
      "17 loss:  1.5037992000579834\n",
      "18 loss:  1.4729678630828857\n",
      "19 loss:  1.4434459209442139\n",
      "20 loss:  1.4151737689971924\n",
      "21 loss:  1.388094425201416\n",
      "22 loss:  1.3621547222137451\n",
      "23 loss:  1.337302803993225\n",
      "24 loss:  1.3134897947311401\n",
      "25 loss:  1.2906692028045654\n",
      "26 loss:  1.268796443939209\n",
      "27 loss:  1.2478290796279907\n",
      "28 loss:  1.2277265787124634\n",
      "29 loss:  1.2084505558013916\n",
      "30 loss:  1.1899641752243042\n",
      "31 loss:  1.1722326278686523\n",
      "32 loss:  1.1552221775054932\n",
      "33 loss:  1.1389011144638062\n",
      "34 loss:  1.1232391595840454\n",
      "35 loss:  1.1082069873809814\n",
      "36 loss:  1.0937771797180176\n",
      "37 loss:  1.079923391342163\n",
      "38 loss:  1.0666203498840332\n",
      "39 loss:  1.0538439750671387\n",
      "40 loss:  1.0415714979171753\n",
      "41 loss:  1.0297809839248657\n",
      "42 loss:  1.018451452255249\n",
      "43 loss:  1.0075632333755493\n",
      "44 loss:  0.9970971345901489\n",
      "45 loss:  0.9870349764823914\n",
      "46 loss:  0.9773596525192261\n",
      "47 loss:  0.968054473400116\n",
      "48 loss:  0.9591037034988403\n",
      "49 loss:  0.9504919052124023\n",
      "50 loss:  0.9422054290771484\n",
      "51 loss:  0.934229850769043\n",
      "52 loss:  0.9265522956848145\n",
      "53 loss:  0.9191601872444153\n",
      "54 loss:  0.9120413661003113\n",
      "55 loss:  0.9051848649978638\n",
      "56 loss:  0.8985792398452759\n",
      "57 loss:  0.8922141194343567\n",
      "58 loss:  0.8860796689987183\n",
      "59 loss:  0.8801664113998413\n",
      "60 loss:  0.8744651079177856\n",
      "61 loss:  0.8689668774604797\n",
      "62 loss:  0.8636635541915894\n",
      "63 loss:  0.8585472106933594\n",
      "64 loss:  0.8536099195480347\n",
      "65 loss:  0.8488448262214661\n",
      "66 loss:  0.8442445993423462\n",
      "67 loss:  0.8398027420043945\n",
      "68 loss:  0.8355128169059753\n",
      "69 loss:  0.8313687443733215\n",
      "70 loss:  0.8273645639419556\n",
      "71 loss:  0.8234950304031372\n",
      "72 loss:  0.819754421710968\n",
      "73 loss:  0.8161379098892212\n",
      "74 loss:  0.8126403093338013\n",
      "75 loss:  0.8092571496963501\n",
      "76 loss:  0.80598384141922\n",
      "77 loss:  0.8028160929679871\n",
      "78 loss:  0.7997497320175171\n",
      "79 loss:  0.7967811822891235\n",
      "80 loss:  0.7939060926437378\n",
      "81 loss:  0.791121244430542\n",
      "82 loss:  0.7884231209754944\n",
      "83 loss:  0.7858083248138428\n",
      "84 loss:  0.7832738161087036\n",
      "85 loss:  0.7808163166046143\n",
      "86 loss:  0.7784331440925598\n",
      "87 loss:  0.7761212587356567\n",
      "88 loss:  0.7738782167434692\n",
      "89 loss:  0.7717013955116272\n",
      "90 loss:  0.7695882320404053\n",
      "91 loss:  0.7675364017486572\n",
      "92 loss:  0.7655437588691711\n",
      "93 loss:  0.7636078596115112\n",
      "94 loss:  0.7617269158363342\n",
      "95 loss:  0.7598987817764282\n",
      "96 loss:  0.7581216096878052\n",
      "97 loss:  0.756393313407898\n",
      "98 loss:  0.7547125220298767\n",
      "99 loss:  0.7530773282051086\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # Forward pass.\n",
    "    pred = linear(x)\n",
    "\n",
    "    # Compute loss.\n",
    "    loss = criterion(pred, y)\n",
    "    print(i, 'loss: ', loss.item())\n",
    "\n",
    "    # Backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Print out the gradients.\n",
    "    #print ('dL/dw: ', linear.weight.grad) \n",
    "    #print ('dL/db: ', linear.bias.grad)\n",
    "\n",
    "    # 1-step gradient descent.\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Опциональный шаг оптимизации на низком уровне** (you can also perform gradient descent at the low level)\n",
    "\n",
    "Комментарии демонстрируют, как можно выполнить шаг оптимизации на низком уровне, обновив параметры модели вручную с использованием градиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
    "# linear.bias.data.sub_(0.01 * linear.bias.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод значения функции потерь после 1 шага оптимизации** (print out the loss after 1-step gradient descent)\n",
    "\n",
    "После обучения циклом 100 раз, выполняется дополнительный прямой проход, и выводится значение функции потерь для оценки эффективности модели после обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 step optimization:  0.7514860033988953\n"
     ]
    }
   ],
   "source": [
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 1 step optimization: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading data from numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "#                     3. Loading data from numpy                     #\n",
    "# ================================================================== #\n",
    "\n",
    "# Create a numpy array.\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "# Convert the numpy array to a torch tensor.\n",
    "y = torch.from_numpy(x)\n",
    "#y = torch.tensor(x)\n",
    "\n",
    "# Convert the torch tensor to a numpy array.\n",
    "z = y.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a numpy array.** Создается двумерный массив NumPy x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the numpy array to a torch tensor.** Массив NumPy x преобразуется в тензор PyTorch y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(x)\n",
    "#y = torch.tensor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закомментированная строка `#y = torch.tensor(x)` предоставляет альтернативный способ преобразования массива NumPy x в тензор PyTorch. Вместо использования torch.from_numpy(x), вы можете просто создать тензор PyTorch напрямую с помощью `torch.tensor(x)`. Оба метода выполняют схожую задачу преобразования данных, но есть небольшая разница в поведении.\n",
    "\n",
    "Основное различие заключается в том, что `torch.from_numpy(x)` создает тензор, который разделяет данные с массивом NumPy x. Это означает, что изменения в тензоре PyTorch будут отражаться в массиве NumPy и наоборот, так как они совместно используют память. С другой стороны, `torch.tensor(x)` создает копию данных, поэтому изменения в тензоре PyTorch не влияют на исходный массив NumPy и наоборот.\n",
    "\n",
    "Зависит от ваших потребностей и требований к управлению данными, какой метод использовать. Если вам нужно разделять данные между NumPy и PyTorch без дополнительной копии, то используйте `torch.from_numpy(x)`. Если вам нужна независимая копия данных для тензора PyTorch, используйте `torch.tensor(x)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the torch tensor to a numpy array.** Тензор PyTorch преобразуется в массив NumPy z:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяется доступность вычислений на графическом процессоре (GPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируются два массива NumPy x и y, каждый из которых содержит 100 000 случайных значений из стандартного нормального распределения (нормальное распределение с средним значением равным 0 и стандартным отклонениемравным 1). Измеряется время выполнения операции скалярного произведения (dot product) массивов NumPy x и y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.48 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "200 µs ± 169 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(100000)\n",
    "y = np.random.randn(100000)\n",
    "%timeit x.dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаются тензоры PyTorch x и y, и оба они находятся на центральном процессоре (CPU). Измеряется время выполнения операции скалярного произведения тензоров PyTorch на CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.43 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "223 µs ± 125 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(np.random.randn(100000)).to('cpu')\n",
    "y = torch.tensor(np.random.randn(100000)).to('cpu')\n",
    "%timeit x.dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаются тензоры PyTorch x и y, и оба они находятся на графическом процессоре (CUDA). Измеряется время выполнения операции скалярного произведения тензоров PyTorch на GPU (CUDA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(np.random.randn(100000)).to('cuda')\n",
    "y = torch.tensor(np.random.randn(100000)).cuda()\n",
    "%timeit x.dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Input pipeline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "#                         4. Input pipeline                          #\n",
    "# ================================================================== #\n",
    "\n",
    "# Download and construct CIFAR-10 dataset.\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True, \n",
    "                                             transform=transforms.ToTensor(),\n",
    "                                             download=True)\n",
    "\n",
    "# Fetch one data pair (read data from disk).\n",
    "image, label = train_dataset[0]\n",
    "print (image.size())\n",
    "print (label)\n",
    "\n",
    "# Data loader (this provides queues and threads in a very simple way).\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# When iteration starts, queue and thread start to load data from files.\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# Mini-batch images and labels.\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "# Actual usage of the data loader is as below.\n",
    "for images, labels in train_loader:\n",
    "    # Training code should be written here.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот код представляет собой пример загрузки и использования датасета CIFAR-10 с использованием библиотеки PyTorch. CIFAR-10 - это популярный набор данных, который содержит 60 000 цветных изображений размером 32x32, разделенных на 10 классов (по 6 000 изображений на класс). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download and construct CIFAR-10 dataset.** Загрузка и создание датасета CIFAR-10:\n",
    "\n",
    "`root` - указывает директорию, в которой будут сохранены данные (если они еще не загружены).\n",
    "\n",
    "`train=True` - указывает, что мы загружаем тренировочный набор данных (вместо тестового).\n",
    "\n",
    "`transform=transforms.ToTensor()` - определяет преобразование данных в тензоры PyTorch.\n",
    "\n",
    "`download=True` - указывает библиотеке загрузить данные, если они еще не скачаны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True, \n",
    "                                             transform=transforms.ToTensor(),\n",
    "                                             download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch one data pair (read data from disk).** Получение одной пары данных:\n",
    "\n",
    "Здесь мы получаем первую пару данных из тренировочного набора. image представляет изображение в формате тензора, а label - метку класса. Мы выводим размер изображения и метку на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "print (image.size())\n",
    "print (label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data loader (this provides queues and threads in a very simple way).** Создание загрузчика данных (Data Loader):\n",
    "\n",
    "Здесь мы создаем загрузчик данных, который управляет пакетами данных для обучения. `batch_size` определяет количество примеров данных в каждом пакете, и `shuffle=True` означает, что данные будут случайно перемешаны перед каждой эпохой обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When iteration starts, queue and thread start to load data from files.** Получение итератора для загрузчика данных:\n",
    "\n",
    "Итератор позволяет перебирать данные по мере необходимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-batch images and labels.**\n",
    "\n",
    "Эта строка извлекает следующий пакет данных (первый пакет) из data_iter, который был создан для загрузчика данных train_loader. images содержит изображения, а labels содержит метки для этого пакета данных. Это полезно, если вы хотите быстро посмотреть на данные или выполнить какие-либо предварительные анализы перед началом обучения модели.\n",
    "\n",
    "p.s. в контексте библиотеки PyTorch и машинного обучения, \"batch\" (пакет) - это группа примеров данных, которые обрабатываются одновременно в ходе обучения модели. Обычно во время обучения модели в PyTorch происходит циклическая обработка всех данных путем разделения их на пакеты. Модель вычисляет градиенты для каждого пакета, и затем эти градиенты используются для обновления параметров модели в процессе градиентного спуска или других методов оптимизации. Пакетный подход делает обучение более эффективным и масштабируемым, особенно при работе с большими объемами данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual usage of the data loader is as below.** Использование загрузчика данных для обучения:\n",
    "\n",
    "В этом цикле мы перебираем пакеты данных, предоставляемые загрузчиком, и обычно обучаем модель машинного обучения на этих данных. Вместо комментария pass вы должны добавить свой собственный код обучения модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    # Training code should be written here.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Создаётся два тензора PyTorch x и y, заполненныых случайными числами из нормального распределения со средним значением 0 и дисперсией 1 (стандартное нормальное распределение). \n",
    "2. Создается объект dataset, который объединяет тензоры x и y в один датасет. Теперь каждая пара (x[i], y[i]) представляет собой один обучающий пример. \n",
    "3. Создается объект loader. Этот DataLoader предоставляет удобный способ загрузки данных в обучающий процесс. \n",
    "\n",
    "    `batch_size`: данные разделяются на мини-пакеты размером 10\n",
    "    \n",
    "    `shuffle=False`: порядок примеров не перемешивается\n",
    "\n",
    "    Этот DataLoader автоматически разделяет данные на мини-пакеты размером 10 и предоставит их в итерируемой форме. Это полезно при обучении моделей на больших наборах данных, когда невозможно загрузить все данные в память сразу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(100, 5) # 100 примеров, каждый имеет 5 признаков\n",
    "y = torch.randn(100, 1) # 100 целевых значений (или меток) для этих примеров\n",
    "dataset = torch.utils.data.TensorDataset(x, y)\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=10, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1084, -0.2851,  1.2174, -0.8970,  0.7005],\n",
      "        [-1.0344,  1.0966,  0.0292,  0.2165,  0.6746],\n",
      "        [ 0.6224,  0.7937, -0.9416,  0.1784, -0.4309],\n",
      "        [ 1.0065,  0.1071, -0.3768,  0.7618, -0.0308],\n",
      "        [-0.3101, -0.5885,  1.0506, -1.2406,  0.8871],\n",
      "        [-0.9963,  1.0351,  2.1234,  0.5735, -0.0910],\n",
      "        [ 1.1783,  0.1793,  0.1165,  0.7647, -0.0882],\n",
      "        [-0.5113,  0.3593, -0.4507,  0.7896, -1.9649],\n",
      "        [-0.1998, -0.3947, -0.3703, -2.2381,  0.2017],\n",
      "        [-2.3404, -0.3899,  0.1733,  2.2053, -0.6725]])\n",
      "tensor([[-1.1190],\n",
      "        [ 0.7378],\n",
      "        [ 0.0999],\n",
      "        [-1.1138],\n",
      "        [-0.1022],\n",
      "        [-0.8227],\n",
      "        [-0.7476],\n",
      "        [ 1.4706],\n",
      "        [-0.0587],\n",
      "        [ 1.4130]])\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in loader: # На каждой итерации, x_batch представляет собой мини-пакет входных данных, \n",
    "                                # а y_batch представляет мини-пакет соответствующих целевых значений\n",
    "    print(x_batch)\n",
    "    print(y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([ 0.1084, -0.2851,  1.2174, -0.8970,  0.7005]), tensor([-1.1190])),\n",
       " tensor([ 0.1084, -0.2851,  1.2174, -0.8970,  0.7005]),\n",
       " tensor([-1.1190]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0], x[0], y[0] # первая пара данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Input pipeline for custom dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "#                5. Input pipeline for custom dataset                 #\n",
    "# ================================================================== #\n",
    "import os\n",
    "# You should build your custom dataset as below.\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, folder_name):\n",
    "        # TODO\n",
    "        # 1. Initialize file paths or a list of file names. \n",
    "        self.folder_name = folder_name\n",
    "        self.files = os.listdir(self.folder_name)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        return self.files[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return len(self.files)\n",
    "\n",
    "# You can then use the prebuilt data loader. \n",
    "custom_dataset = CustomDataset(folder_name='.')\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                           batch_size=4, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот код представляет собой **шаблон для создания собственного набора данных (custom dataset) в PyTorch**\n",
    "\n",
    "Разберем, что делает каждый метод в этом классе:\n",
    "\n",
    "1. `__init__(self, folder_name)`\n",
    "\n",
    "    Этот метод инициализирует объект класса CustomDataset.\n",
    "    \n",
    "    – Принимаем folder_name в качестве аргумента, что предполагает, что мы хотим создать набор данных, используя файлы из определенной папки (параметр folder_name представляет путь к папке, содержащей наши данные)\n",
    "    \n",
    "    – Получаем список файлов в указанной папке с помощью `os.listdir()` и сохраняем в атрибут self.files. Это будут наши файлы данных. \n",
    "    \n",
    "    Мы можем настроить этот метод для чтения файлов или создания списка файлов в нашей папке данных.\n",
    "\n",
    "2. `__getitem__(self, index)`\n",
    "\n",
    "    Этот метод используется для получения элемента данных из нашего набора данных по указанному индексу.\n",
    "    \n",
    "    – Принимаем параметр index, который представляет индекс элемента, который мы хотим получить\n",
    "    \n",
    "    – Считываем данные из файла, соответствующего указанному индексу. В текущей реализации этого метода отсутствует код для считывания данных из файла. Мы должны добавить этот код в соответствии с форматом ваших данных (например, с использованием `numpy.fromfile` для бинарных данных или `PIL.Image.open` для изображений)\n",
    "    \n",
    "    – Предобрабатываем считанные данные (например, с использованием трансформаций из torchvision)\n",
    "    \n",
    "    – Возвращаем пару данных (например, изображение и метку)\n",
    "\n",
    "3. `__len__(self)`\n",
    "\n",
    "    Этот метод возвращает общее количество элементов в нашем наборе данных. В текущем шаблоне он возвращает количество файлов в списке self.files\n",
    "\n",
    "Когда мы создадим экземпляр нашего CustomDataset и передадим его в DataLoader, PyTorch будет использовать методы `__getitem__` и `__len__` для загрузки и итерации по нашим данным во время обучения нашей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can then use the prebuilt data loader**\n",
    "\n",
    "После создания нашего пользовательского датасета custom_dataset, мы создали DataLoader, который позволяет нам эффективно загружать данные в процессе обучения модели, со следующими параметрами:\n",
    "\n",
    "`dataset=custom_dataset`: указали custom_dataset как источник данных для train_loader. Это значит, что train_loader будет загружать данные из нашего пользовательского датасета\n",
    "\n",
    "`batch_size=4`: установили размер мини-пакета, в каждой итерации train_loader будет предоставлять мини-пакеты данных размером 4 примера\n",
    "\n",
    "`shuffle=True`: указали, что данные в train_loader будут перемешиваться перед каждой эпохой обучения. Это важно для обеспечения случайного порядка примеров и улучшения обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(folder_name='.')\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                           batch_size=4, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0. Pytorch.ipynb'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', '1. Pytorch basics.ipynb', '3. Logistic regression.ipynb', 'deep learning 60min blitz']\n"
     ]
    }
   ],
   "source": [
    "for names in train_loader:\n",
    "    print(names)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`len(a)` и `a.__len__()` возвращают длину списка a. Встроенная функция `len()` является более предпочтительным и читаемым способом получения длины последовательности (списка, кортежа и других), чем явный вызов метода `__len__()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "len(a), a.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция dir(a) возвращает список всех атрибутов и методов объекта a, включая встроенные и пользовательские\n",
    "\n",
    "`a[1]` и `a.__getitem__(1)` выполняют одно и то же действие – получение элемента с индексом 1 из списка a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(a)\n",
    "a[1], a.__getitem__(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "#                        6. Pretrained model                         #\n",
    "# ================================================================== #\n",
    "\n",
    "'''Этот код показывает, как загрузить предварительно обученную модель, \n",
    "настроить её для тонкой настройки и выполнить прямой проход для получения предсказаний'''\n",
    "\n",
    "# Download and load the pretrained ResNet-18.\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# If you want to finetune only the top layer of the model, set as below.\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the top layer for finetuning.\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example.\n",
    "\n",
    "# Forward pass.\n",
    "images = torch.randn(64, 3, 224, 224)\n",
    "outputs = resnet(images)\n",
    "print (outputs.size())     # (64, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем предварительно обученную модель ResNet-18, то есть создаём экземпляр модели ResNet-18 с предварительно загруженными весами, которые были обучены на большом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\iveel/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:23<00:00, 2.02MB/s]\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы хотим выполнить точную настройку (fine-tuning), но только для верхнего слоя модели, мы проходимся по всем параметрам модели resnet и устанавливаем `requires_grad=False`. Это означает, что градиенты не будут вычисляться для этих параметров во время обратного распространения ошибки. В результате, только верхний слой будет обучаться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы заменяем верхний слой модели (.fc представляет собой атрибут, который обозначает верхний (полносвязанный) слой модели) собственным линейным слоем, представленным как `nn.Linear(resnet.fc.in_features, 100)`. Этот слой принимает признаки, выходящие из предыдущего слоя модели, и преобразует их в 100 классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cоздаём тензор images, представляющий входные изображения размером (64, 3, 224, 224), где 64 – размер мини-пакета, 3 – количество каналов (RGB), 224x224 – размер изображения\n",
    "\n",
    "Выполняем прямой проход (forward pass) для входных изображений images с использованием модели resnet. Когда вызывается `resnet(images)`, происходит следующее:\n",
    "\n",
    "1. Входные изображения images, размером (64, 3, 224, 224), передаются через модель resnet\n",
    "\n",
    "2. Модель выполняет серию сверточных и пулинговых слоев, которые извлекают признаки из изображений\n",
    "\n",
    "3. Затем, полученные признаки проходят через верхний (полносвязанный) слой, который был заменен в предыдущем коде с использованием `nn.Linear(resnet.fc.in_features, 100)`. Этот слой преобразует признаки в предсказания для 100 классов (в данном случае)\n",
    "\n",
    "4. Выходные предсказания сохраняются в тензор outputs\n",
    "\n",
    "Получаем тензор размером (64, 100), где 64 – размер мини-пакета, а 100 – количество классов, предсказываемых моделью после точной настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100])\n"
     ]
    }
   ],
   "source": [
    "images = torch.randn(64, 3, 224, 224)\n",
    "outputs = resnet(images)\n",
    "print (outputs.size())     # (64, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save and load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================== #\n",
    "#                      7. Save and load the model                    #\n",
    "# ================================================================== #\n",
    "\n",
    "# Save and load the entire model.\n",
    "torch.save(resnet, 'model.ckpt')\n",
    "model = torch.load('model.ckpt')\n",
    "\n",
    "# Save and load only the model parameters (recommended).\n",
    "torch.save(resnet.state_dict(), 'params.ckpt')\n",
    "resnet.load_state_dict(torch.load('params.ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует два основных способа сохранения и загрузки модели в PyTorch:\n",
    "\n",
    "1. Сохранение и загрузка всей модели:\n",
    "\n",
    "    С помощью `torch.save(resnet, 'model.ckpt')` мы сохраняем всю модель resnet в файл 'model.ckpt'. Это включает в себя архитектуру модели и значения всех параметров, в том числе веса\n",
    "    \n",
    "    С помощью `torch.load('model.ckpt')` мы загружаем модель целиком обратно в переменную model. Это позволяет нам продолжить использовать модель в том виде, в котором она была на момент сохранения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet, 'model.ckpt')\n",
    "model = torch.load('model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Сохранение и загрузка только параметров модели:\n",
    "\n",
    "    С помощью `torch.save(resnet.state_dict(), 'params.ckpt')` мы сохраняем только параметры модели (веса) в файл 'params.ckpt'. Архитектура модели не включается в сохранение\n",
    "    \n",
    "    С помощью `resnet.load_state_dict(torch.load('params.ckpt'))` мы загружаем параметры обратно в модель resnet. Этот метод полезен, когда мы хотим перенести веса обученной модели на другую модель с аналогичной архитектурой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(resnet.state_dict(), 'params.ckpt')\n",
    "resnet.load_state_dict(torch.load('params.ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно рекомендуется использовать второй способ, сохраняя и загружая только параметры модели. Это делает файлы сохранения более компактными и позволяет более гибко управлять архитектурой модели при необходимости"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
